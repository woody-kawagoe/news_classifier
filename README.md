# Usage

(IPアドレス)/naive\_bayesにアクセスするとフォーム画面が表示される。
フォームにGunosyのニュースのURLを入力すると分類結果画面に遷移する。

# Packages

+ python 3.5.0
+ django 1.10.2
+ mecab 0.996
+ mecab-ipadic-neologd
+ python-mecab3 0.7
+ beautifulsoup4 4.5.1
+ pandas 0.19.0

# View

## form フォーム画面
フォームにURLを入力で送信ボタンを押すと、URLをPOSTで送信する。
## result 結果画面
formから送信された分類結果を表示する。
同時に各カテゴリの推定スコア(事前確率log(P(doc|cat)))を表示する。
この推定スコアが高いほどそのカテゴリである確率が高いと判断する。

# Classifier

事後確率P(cat|doc)はベイズの定理を用いると次の式で表せる。

P(cat|doc)=P(cat)P(doc|cat)/P(doc)

P(cat)は各カテゴリの生起確率である。
今回の教師データでは各カテゴリのニュース数は全て100件である。
そのためどのカテゴリの生起確率も等しい。
P(doc)はそのニュースの生起確率である。
これはどのニュースでも1/（全ニュース数）となるので確率は等しい。
そのため事前確率P(doc|cat)さえ分かれば事後確率P(cat|doc)の順位がわかる。
事前確率P(doc|cat)はカテゴリcatの時の単語word\_iが
出現する確率P(word\_i|cat)の総積である。
P(word\_i|cat)はカテゴリcatでの単語word\_iの出現回数を
カテゴリcatでの全単語の出現回数で割った値である。
この値は小さい値で、総積の事前確率がアンダーフローを起こす可能性がある。
そのため対数をとり、その総和を求める。
対数をとっても大小関係は不変であるためlog(P(doc|cat))が
もっとも大きいカテゴリを分類結果として返す。
